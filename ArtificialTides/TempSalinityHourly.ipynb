{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Back the Tides - CIOPS\n",
    "An effort to make the daily files more accurate as they are currently lacking the tidal pumping that is so important to the flow of the Salish Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import gsw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just 2018 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "31-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "startday = [dt.datetime(2017,12,17)+dt.timedelta(days=i) for i in range(int(399))]\n",
    "print(startday[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "folders = [dt.datetime(2017,12,17)+dt.timedelta(days=7*(i+1)) for i in range(int(57))]\n",
    "print(folders[-1])\n",
    "folders = np.repeat(folders,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [startday[0],startday[1]]\n",
    "folderday = [folders[0], folders[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 12, 17, 0, 0), datetime.datetime(2017, 12, 18, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2017, 12, 24, 0, 0), datetime.datetime(2017, 12, 24, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(folderday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/ocean/mdunphy/CIOPSW-BC12/\")\n",
    "\n",
    "drop_vars = (\n",
    "    \"deptht_bounds\",\"time_counter_bounds\",\"time_instant_bounds\",\n",
    ")\n",
    "\n",
    "files = [sorted(path.glob(\"{:%Y%m%d}00/BC12_1d_grid_T_{:%Y%m%d}_{:%Y%m%d}.nc\".format(folderday[i], date[i], date[i]))) for i in range(len(date))]\n",
    "\n",
    "mydata = xr.open_mfdataset(files, drop_variables=drop_vars)\n",
    "sal = mydata['so']\n",
    "potT = mydata['thetao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all land values with nan so that math isn't done on them\n",
    "sal = sal.where(sal != 0)\n",
    "potT = potT.where(potT != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30488477"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(potT[0,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#needs 2 step conversion, first CT_from_pt and them t_from_CT\n",
    "CT = gsw.CT_from_pt(sal,potT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30488477"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(CT[0,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = gsw.t_from_CT(sal,CT,potT.deptht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30488477"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(T[0,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:\n",
      "13.2928095\n",
      "13.52708962780418\n",
      "13.303625922952929\n",
      "min:\n",
      "1.0356041\n",
      "1.0369278205172834\n",
      "1.3827944931701688\n"
     ]
    }
   ],
   "source": [
    "# ok clearly not a stright up number of nan that is the issue - maybe its because some temperature values are unreasonable?\n",
    "print('max:')\n",
    "print(np.max(potT[0,:,:,:]).values)\n",
    "print(np.max(CT[0,:,:,:]).values)\n",
    "print(np.max(T[0,:,:,:]).values)\n",
    "print('min:')\n",
    "print(np.min(potT[0,:,:,:]).values)\n",
    "print(np.min(CT[0,:,:,:]).values)\n",
    "print(np.min(T[0,:,:,:]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = T.where(T>1,0) #the conversions mess with all the land values, convert these back to 0.. the region doesnt go lower than 1 so this is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpolate + resample to get it in an hourly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_interp = sal.resample(time_counter=\"1H\", loffset=dt.timedelta(hours=1)).interpolate(\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbeutel/.local/lib/python3.8/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "sal_new = sal_interp.isel(time_counter = np.arange(0,24,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_new = sal_new.rename('vosaline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vosaline': {'zlib': True, 'complevel': 4, '_FillValue': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding={\n",
    "          \"vosaline\": {\"zlib\": True, \"complevel\": 4, \"_FillValue\": 0}\n",
    "}\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/ocean/rbeutel/data/'\n",
    "sal_new.to_netcdf(str(path)+'{:%Y%m}/S_new_{:%Y%m%d}.nc'.format(date[1],date[1]), encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_interp = T.resample(time_counter=\"1H\", loffset=dt.timedelta(hours=1)).interpolate(\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbeutel/.local/lib/python3.8/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "T_new = T_interp.isel(time_counter = np.arange(0,24,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_new = T_new.rename('votemper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'votemper': {'zlib': True, 'complevel': 4, '_FillValue': 0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding={\n",
    "          \"votemper\": {\"zlib\": True, \"complevel\": 4, \"_FillValue\": 0}\n",
    "}\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_new.to_netcdf(str(path)+'{:%Y%m}/T_new_{:%Y%m%d}.nc'.format(date[1],date[1]), encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OceanParcels",
   "language": "python",
   "name": "oceanparcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
