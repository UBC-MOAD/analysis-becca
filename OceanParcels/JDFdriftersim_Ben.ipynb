{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drifter Simmulation in the JDF\n",
    "Based off of code from https://github.com/UBC-MOAD/PythonNotes/blob/master/OceanParcelsRecipes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ParcelsRandom ==> /tmp/parcels-2919/libparcels_random_97c5f831-67b8-4b05-86ca-a7e57d00ab46.so\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from matplotlib import pyplot as plt, animation\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from IPython.display import HTML\n",
    "from salishsea_tools import nc_tools, places\n",
    "\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, AdvectionRK4, AdvectionRK4_3D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Fieldset Functions\n",
    "The following functions handle the syntax of defining the forcing files into a parcels.FieldSet object - get it into the right format for OceanParcels to load forcing data on-the-fly and handle all of the interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fieldset_from_nemo(daterange, coords, flat=True):\n",
    "    \"\"\"Generate a fieldset from a hourly SalishSeaCast forcing fields\n",
    "    over daterange.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate sequential list of forcing file prefixes\n",
    "    prefixes = [\n",
    "        nc_tools.get_hindcast_prefix(daterange[0] + timedelta(days=d))\n",
    "        for d in range(np.diff(daterange)[0].days + 1)\n",
    "    ]\n",
    "\n",
    "    # Predefine fieldset argument dictionaries\n",
    "    filenames, variables, dimensions = {}, {}, {}\n",
    "\n",
    "    # Define dict fields for each variable\n",
    "    for var, name in zip(['U', 'V', 'W'], ['vozocrtx', 'vomecrty', 'vovecrtz']):\n",
    "        \n",
    "        # Exclude vertical velocity if 2D\n",
    "        if flat:\n",
    "            if var == 'W': break\n",
    "\n",
    "        # Dict of filenames containing the coordinate and forcing variables\n",
    "        datafiles = [prefix + f'_grid_{var}.nc' for prefix in prefixes]\n",
    "        filenames[var] = {'lon': coords, 'lat': coords, 'data': datafiles}\n",
    "\n",
    "        # NEMO variable name\n",
    "        variables[var] = name\n",
    "\n",
    "        # Dict of NEMO coordinate names (f-points)\n",
    "        dimensions[var] = {'lon': 'glamf', 'lat': 'gphif', 'time': 'time_counter'}\n",
    "        \n",
    "        # Add depth fields if 3D (f-points are on W grid)\n",
    "        if not flat:\n",
    "            filenames[var]['depth'] = prefixes[0] + '_grid_W.nc'\n",
    "            dimensions[var]['depth'] = 'depthw'\n",
    "\n",
    "    # Load NEMO forcing into fieldset\n",
    "    field_set = FieldSet.from_nemo(filenames, variables, dimensions, field_chunksize='auto')\n",
    "    \n",
    "    return field_set\n",
    "\n",
    "\n",
    "def append_auxiliary_forcing(fieldset, model, daterange, coords_path):\n",
    "    \"\"\"Append hourly GEM or WW3 forcing fields to a fieldset over daterange\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate sequential list of forcing files\n",
    "    datafiles = [\n",
    "        getattr(nc_tools, f'get_{model}_path')(daterange[0] + timedelta(days=d))\n",
    "        for d in range(np.diff(daterange)[0].days + 1)\n",
    "    ]\n",
    "    \n",
    "    # Assign variable suffix and dimensions definitions according to model\n",
    "    if model == 'GEM':\n",
    "        suffix = '_wind'\n",
    "        dimensions = {'lon': 'nav_lon', 'lat': 'nav_lat', 'time': 'time_counter'}\n",
    "    elif model == 'WW3':\n",
    "        suffix = 'uss'\n",
    "        dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "    else:\n",
    "        raise ValueError(f'Unknown surface forcing model: {model}')\n",
    "    \n",
    "    # Define coordinates file path and create if necessary\n",
    "    #  - only method I've had success with for correcting lons\n",
    "    coords = os.path.join(coords_path, f'{model}_grid.nc')\n",
    "    if not os.path.exists(coords):\n",
    "        with xr.open_dataset(datafiles[0]) as ds:\n",
    "            data_vars = [dimensions['time']] + list(ds.data_vars)\n",
    "            if model == 'GEM':\n",
    "                for key in ['lon', 'lat']: data_vars.remove(dimensions[key])\n",
    "            ds = ds.drop_vars(data_vars)\n",
    "            ds.update({dimensions['lon']: ds[dimensions['lon']] - 360})\n",
    "            ds.to_netcdf(coords)\n",
    "    \n",
    "    # Filenames dict\n",
    "    filenames = {'lon': coords, 'lat': coords, 'data': datafiles}\n",
    "    \n",
    "    # Load u velocity\n",
    "    u = Field.from_netcdf(\n",
    "        filenames, f'u{suffix}', dimensions, fieldtype='U', field_chunksize='auto',\n",
    "    )\n",
    "    \n",
    "    # Load v velocity with u grid\n",
    "    v = Field.from_netcdf(\n",
    "        filenames, f'v{suffix}', dimensions, fieldtype='V', field_chunksize='auto',\n",
    "        grid=u.grid, dataFiles=u.dataFiles,\n",
    "    )\n",
    "\n",
    "    # Add velocity fields to fieldset\n",
    "    fieldset.add_field(u)\n",
    "    fieldset.add_field(v)\n",
    "\n",
    "    # Make new vector field from u and v for use in kernels\n",
    "    u, v = [getattr(fieldset, f'{var}{suffix}') for var in ('u', 'v')]\n",
    "    fieldset.add_vector_field(VectorField(f\"UV_{model}\", u, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Kernel Functions\n",
    "Used to prescribe particle behavior in OceanParcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WindDrift(particle, fieldset, time):\n",
    "    (uw, vw) = fieldset.UV_GEM[time, particle.depth, particle.lat, particle.lon]\n",
    "    particle.lon += uw * 0.03 * particle.dt\n",
    "    particle.lat += vw * 0.03 * particle.dt\n",
    "\n",
    "\n",
    "def StokesDrift(particle, fieldset, time):\n",
    "    (us, vs) = fieldset.UV_WW3[time, particle.depth, particle.lat, particle.lon]\n",
    "    particle.lon += us * particle.dt\n",
    "    particle.lat += vs * particle.dt\n",
    "\n",
    "\n",
    "def DeleteParticle(particle, fieldset, time): #Susan had this one in her code but not the others\n",
    "    print(f'Particle {particle.id} lost !! [{particle.lon}, {particle.lat}, {particle.depth}, {particle.time}]')\n",
    "    particle.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and filenames\n",
    "paths = {\n",
    "    'coords': '/ocean/rbeutel/MEOPAR/grid/coordinates_seagrid_SalishSea201702.nc',\n",
    "    'mask': '/ocean/rbeutel/MEOPAR/grid/mesh_mask201702.nc',\n",
    "    'results':  './results',\n",
    "}\n",
    "\n",
    "# Load coords and mask files and extract grid variables\n",
    "coords, mask = [xr.open_dataset(paths[key], decode_times=False) for key in ('coords', 'mask')]\n",
    "gridlon, gridlat = [coords[key][0, ...].values for key in ('glamt', 'gphit')]\n",
    "tmask = mask.tmask[0, 0, ...].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define release parameters\n",
    "location = 'Juan de Fuca Strait'\n",
    "n = 100   # number of particles\n",
    "r = 50   # radius of particle cloud [m]\n",
    "\n",
    "# Create Gaussian distribution around release point\n",
    "mean, cov = [0, 0], [[r**2, 0], [0, r**2]]\n",
    "x_offset, y_offset = np.random.multivariate_normal(mean, cov, n).T\n",
    "lon, lat = places.PLACES[location]['lon lat']\n",
    "lons = lon + x_offset / 111000 / np.cos(np.deg2rad(lat))\n",
    "lats = lat + y_offset / 111000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time, duration and timestep\n",
    "start = datetime(2019, 1, 1, 12, 30, 0)\n",
    "duration = timedelta(days=3)\n",
    "dt = timedelta(seconds=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcing daterange (I add 1-day buffers)\n",
    "daterange = [start - timedelta(days=1), start + duration + timedelta(days=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output file prefix\n",
    "strings = [location] + [t.strftime('%Y%m%dT%H%M%S') for t in (start, start + duration)]\n",
    "prefix = os.path.join(paths['results'], '_'.join(strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Surface Drift Simmulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: File /data/bmoorema/MEOPAR/grid/coordinates_seagrid_SalishSea201702.nc could not be decoded properly by xarray (version 0.16.2).\n",
      "         It will be opened with no decoding. Filling values might be wrongly parsed.\n",
      "WARNING: Casting lon data to np.float32\n",
      "WARNING: Casting lat data to np.float32\n",
      "WARNING: Casting depth data to np.float32\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "Field received an unexpected keyword argument \"field_chunksize\" (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/rbeutel/anaconda3/envs/OceanParcels/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3427\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-10-aee06b11aea5>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    fieldset = fieldset_from_nemo(daterange, paths['coords'])\n",
      "  File \u001b[1;32m\"<ipython-input-3-871500d836ce>\"\u001b[0m, line \u001b[1;32m38\u001b[0m, in \u001b[1;35mfieldset_from_nemo\u001b[0m\n    field_set = FieldSet.from_nemo(filenames, variables, dimensions, field_chunksize='auto')\n",
      "  File \u001b[1;32m\"/home/rbeutel/anaconda3/envs/OceanParcels/lib/python3.8/site-packages/parcels/fieldset.py\"\u001b[0m, line \u001b[1;32m487\u001b[0m, in \u001b[1;35mfrom_nemo\u001b[0m\n    fieldset = cls.from_c_grid_dataset(filenames, variables, dimensions, mesh=mesh, indices=indices, time_periodic=time_periodic,\n",
      "  File \u001b[1;32m\"/home/rbeutel/anaconda3/envs/OceanParcels/lib/python3.8/site-packages/parcels/fieldset.py\"\u001b[0m, line \u001b[1;32m598\u001b[0m, in \u001b[1;35mfrom_c_grid_dataset\u001b[0m\n    return cls.from_netcdf(filenames, variables, dimensions, mesh=mesh, indices=indices, time_periodic=time_periodic,\n",
      "  File \u001b[1;32m\"/home/rbeutel/anaconda3/envs/OceanParcels/lib/python3.8/site-packages/parcels/fieldset.py\"\u001b[0m, line \u001b[1;32m409\u001b[0m, in \u001b[1;35mfrom_netcdf\u001b[0m\n    fields[var] = Field.from_netcdf(paths, (var, name), dims, inds, grid=grid, mesh=mesh, timestamps=timestamps,\n",
      "  File \u001b[1;32m\"/home/rbeutel/anaconda3/envs/OceanParcels/lib/python3.8/site-packages/parcels/field.py\"\u001b[0m, line \u001b[1;32m451\u001b[0m, in \u001b[1;35mfrom_netcdf\u001b[0m\n    return cls(variable, data, grid=grid, timestamps=timestamps,\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/rbeutel/anaconda3/envs/OceanParcels/lib/python3.8/site-packages/parcels/field.py\"\u001b[0;36m, line \u001b[0;32m205\u001b[0;36m, in \u001b[0;35m__init__\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise SyntaxError('Field received an unexpected keyword argument \"%s\"' % list(kwargs.keys())[0])\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Field received an unexpected keyword argument \"field_chunksize\"\n"
     ]
    }
   ],
   "source": [
    "# Load SalishSeaCast results into fieldset\n",
    "fieldset = fieldset_from_nemo(daterange, paths['coords'])\n",
    "\n",
    "# Append GEM and WW3 results into fieldset\n",
    "for model in ['GEM', 'WW3']:\n",
    "    append_auxiliary_forcing(fieldset, model, daterange, paths['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fieldset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e4418092ccdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute NEMO-only, 2D run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParticleSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfieldset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJITParticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdvectionRK4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParticleFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_NEMO_2D.nc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m pset.execute(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fieldset' is not defined"
     ]
    }
   ],
   "source": [
    "# Execute NEMO-only, 2D run\n",
    "pset = ParticleSet.from_list(fieldset, JITParticle, lon=lons, lat=lats, time=np.repeat(start, n))\n",
    "kernel = AdvectionRK4\n",
    "output_file = pset.ParticleFile(name=prefix + '_NEMO_2D.nc', outputdt=timedelta(hours=1))\n",
    "pset.execute(\n",
    "    kernel, runtime=duration, dt=dt, output_file=output_file,\n",
    "    recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OceanParcels",
   "language": "python",
   "name": "oceanparcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
