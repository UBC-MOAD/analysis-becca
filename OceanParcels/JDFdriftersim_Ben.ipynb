{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drifter Simmulation in the JDF\n",
    "Based off of code from https://github.com/UBC-MOAD/PythonNotes/blob/master/OceanParcelsRecipes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from matplotlib import pyplot as plt, animation\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from IPython.display import HTML\n",
    "from salishsea_tools import nc_tools, places\n",
    "\n",
    "from parcels import FieldSet, Field, VectorField, ParticleSet, JITParticle, ErrorCode, AdvectionRK4, AdvectionRK4_3D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Fieldset Functions\n",
    "The following functions handle the syntax of defining the forcing files into a parcels.FieldSet object - get it into the right format for OceanParcels to load forcing data on-the-fly and handle all of the interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fieldset_from_nemo(daterange, coords, flat=True):\n",
    "    \"\"\"Generate a fieldset from a hourly SalishSeaCast forcing fields\n",
    "    over daterange.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate sequential list of forcing file prefixes\n",
    "    prefixes = [\n",
    "        nc_tools.get_hindcast_prefix(daterange[0] + timedelta(days=d))\n",
    "        for d in range(np.diff(daterange)[0].days + 1)\n",
    "    ]\n",
    "\n",
    "    # Predefine fieldset argument dictionaries\n",
    "    filenames, variables, dimensions = {}, {}, {}\n",
    "\n",
    "    # Define dict fields for each variable\n",
    "    for var, name in zip(['U', 'V', 'W'], ['vozocrtx', 'vomecrty', 'vovecrtz']):\n",
    "        \n",
    "        # Exclude vertical velocity if 2D\n",
    "        if flat:\n",
    "            if var == 'W': break\n",
    "\n",
    "        # Dict of filenames containing the coordinate and forcing variables\n",
    "        datafiles = [prefix + f'_grid_{var}.nc' for prefix in prefixes]\n",
    "        filenames[var] = {'lon': coords, 'lat': coords, 'data': datafiles}\n",
    "\n",
    "        # NEMO variable name\n",
    "        variables[var] = name\n",
    "\n",
    "        # Dict of NEMO coordinate names (f-points)\n",
    "        dimensions[var] = {'lon': 'glamf', 'lat': 'gphif', 'time': 'time_counter'}\n",
    "        \n",
    "        # Add depth fields if 3D (f-points are on W grid)\n",
    "        if not flat:\n",
    "            filenames[var]['depth'] = prefixes[0] + '_grid_W.nc'\n",
    "            dimensions[var]['depth'] = 'depthw'\n",
    "\n",
    "    # Load NEMO forcing into fieldset\n",
    "    field_set = FieldSet.from_nemo(filenames, variables, dimensions)#, field_chunksize='auto')\n",
    "    \n",
    "    return field_set\n",
    "\n",
    "\n",
    "def append_auxiliary_forcing(fieldset, model, daterange, coords_path):\n",
    "    \"\"\"Append hourly GEM or WW3 forcing fields to a fieldset over daterange\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate sequential list of forcing files\n",
    "    datafiles = [\n",
    "        getattr(nc_tools, f'get_{model}_path')(daterange[0] + timedelta(days=d))\n",
    "        for d in range(np.diff(daterange)[0].days + 1)\n",
    "    ]\n",
    "    \n",
    "    # Assign variable suffix and dimensions definitions according to model\n",
    "    if model == 'GEM':\n",
    "        suffix = '_wind'\n",
    "        dimensions = {'lon': 'nav_lon', 'lat': 'nav_lat', 'time': 'time_counter'}\n",
    "    elif model == 'WW3':\n",
    "        suffix = 'uss'\n",
    "        dimensions = {'lon': 'longitude', 'lat': 'latitude', 'time': 'time'}\n",
    "    else:\n",
    "        raise ValueError(f'Unknown surface forcing model: {model}')\n",
    "    \n",
    "    # Define coordinates file path and create if necessary\n",
    "    #  - only method I've had success with for correcting lons\n",
    "    coords = os.path.join(coords_path, f'{model}_grid.nc')\n",
    "    if not os.path.exists(coords):\n",
    "        with xr.open_dataset(datafiles[0]) as ds:\n",
    "            data_vars = [dimensions['time']] + list(ds.data_vars)\n",
    "            if model == 'GEM':\n",
    "                for key in ['lon', 'lat']: data_vars.remove(dimensions[key])\n",
    "            ds = ds.drop_vars(data_vars)\n",
    "            ds.update({dimensions['lon']: ds[dimensions['lon']] - 360})\n",
    "            ds.to_netcdf(coords)\n",
    "    \n",
    "    # Filenames dict\n",
    "    filenames = {'lon': coords, 'lat': coords, 'data': datafiles}\n",
    "    \n",
    "    # Load u velocity\n",
    "    u = Field.from_netcdf(\n",
    "        filenames, f'u{suffix}', dimensions, fieldtype='U')#, field_chunksize='auto',\n",
    "    #)\n",
    "    \n",
    "    # Load v velocity with u grid\n",
    "    v = Field.from_netcdf(\n",
    "        filenames, f'v{suffix}', dimensions, fieldtype='V',#, field_chunksize='auto',\n",
    "        grid=u.grid, dataFiles=u.dataFiles,\n",
    "    )\n",
    "\n",
    "    # Add velocity fields to fieldset\n",
    "    fieldset.add_field(u)\n",
    "    fieldset.add_field(v)\n",
    "\n",
    "    # Make new vector field from u and v for use in kernels\n",
    "    u, v = [getattr(fieldset, f'{var}{suffix}') for var in ('u', 'v')]\n",
    "    fieldset.add_vector_field(VectorField(f\"UV_{model}\", u, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Kernel Functions\n",
    "Used to prescribe particle behavior in OceanParcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WindDrift(particle, fieldset, time):\n",
    "    (uw, vw) = fieldset.UV_GEM[time, particle.depth, particle.lat, particle.lon]\n",
    "    particle.lon += uw * 0.03 * particle.dt\n",
    "    particle.lat += vw * 0.03 * particle.dt\n",
    "\n",
    "\n",
    "def StokesDrift(particle, fieldset, time):\n",
    "    (us, vs) = fieldset.UV_WW3[time, particle.depth, particle.lat, particle.lon]\n",
    "    particle.lon += us * particle.dt\n",
    "    particle.lat += vs * particle.dt\n",
    "\n",
    "\n",
    "def DeleteParticle(particle, fieldset, time): #Susan had this one in her code but not the others\n",
    "    print(f'Particle {particle.id} lost !! [{particle.lon}, {particle.lat}, {particle.depth}, {particle.time}]')\n",
    "    particle.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and filenames\n",
    "paths = {\n",
    "    'coords': '/ocean/rbeutel/MEOPAR/grid/coordinates_seagrid_SalishSea201702.nc',\n",
    "    'mask': '/ocean/rbeutel/MEOPAR/grid/mesh_mask201702.nc',\n",
    "    'results':  './results',\n",
    "}\n",
    "\n",
    "# Load coords and mask files and extract grid variables\n",
    "coords, mask = [xr.open_dataset(paths[key], decode_times=False) for key in ('coords', 'mask')]\n",
    "gridlon, gridlat = [coords[key][0, ...].values for key in ('glamt', 'gphit')]\n",
    "tmask = mask.tmask[0, 0, ...].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define release parameters\n",
    "location = 'Juan de Fuca Strait'\n",
    "n = 100   # number of particles\n",
    "r = 50   # radius of particle cloud [m]\n",
    "\n",
    "# Create Gaussian distribution around release point\n",
    "mean, cov = [0, 0], [[r**2, 0], [0, r**2]]\n",
    "x_offset, y_offset = np.random.multivariate_normal(mean, cov, n).T\n",
    "lon, lat = places.PLACES[location]['lon lat']\n",
    "lons = lon + x_offset / 111000 / np.cos(np.deg2rad(lat))\n",
    "lats = lat + y_offset / 111000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time, duration and timestep\n",
    "start = datetime(2019, 1, 1, 12, 30, 0)\n",
    "duration = timedelta(days=3)\n",
    "dt = timedelta(seconds=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcing daterange (I add 1-day buffers)\n",
    "daterange = [start - timedelta(days=1), start + duration + timedelta(days=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output file prefix\n",
    "strings = [location] + [t.strftime('%Y%m%dT%H%M%S') for t in (start, start + duration)]\n",
    "prefix = os.path.join(paths['results'], '_'.join(strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Surface Drift Simmulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'salishsea_tools.nc_tools' has no attribute 'get_WW3_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-aee06b11aea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Append GEM and WW3 results into fieldset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'GEM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WW3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mappend_auxiliary_forcing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfieldset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaterange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-03010d64c0df>\u001b[0m in \u001b[0;36mappend_auxiliary_forcing\u001b[0;34m(fieldset, model, daterange, coords_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Generate sequential list of forcing files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     datafiles = [\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc_tools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'get_{model}_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaterange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaterange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-03010d64c0df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Generate sequential list of forcing files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     datafiles = [\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc_tools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'get_{model}_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaterange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaterange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     ]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'salishsea_tools.nc_tools' has no attribute 'get_WW3_path'"
     ]
    }
   ],
   "source": [
    "# Load SalishSeaCast results into fieldset\n",
    "fieldset = fieldset_from_nemo(daterange, paths['coords'])\n",
    "\n",
    "# Append GEM and WW3 results into fieldset\n",
    "for model in ['GEM', 'WW3']:\n",
    "    append_auxiliary_forcing(fieldset, model, daterange, paths['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fieldset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e4418092ccdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Execute NEMO-only, 2D run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParticleSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfieldset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJITParticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdvectionRK4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParticleFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_NEMO_2D.nc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m pset.execute(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fieldset' is not defined"
     ]
    }
   ],
   "source": [
    "# Execute NEMO-only, 2D run\n",
    "pset = ParticleSet.from_list(fieldset, JITParticle, lon=lons, lat=lats, time=np.repeat(start, n))\n",
    "kernel = AdvectionRK4\n",
    "output_file = pset.ParticleFile(name=prefix + '_NEMO_2D.nc', outputdt=timedelta(hours=1))\n",
    "pset.execute(\n",
    "    kernel, runtime=duration, dt=dt, output_file=output_file,\n",
    "    recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OceanParcels",
   "language": "python",
   "name": "oceanparcels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
