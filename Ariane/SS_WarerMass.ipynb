{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where do the water masses go in the Salish Sea?\n",
    "Using the same water mass seperations as in CIOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interp\n",
    "# from scipy.stats import binned_statistic_2d\n",
    "# import cmocean.cm as cm\n",
    "# from matplotlib.patches import Rectangle\n",
    "# from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mydata, starttime, endtime):\n",
    "    salt = mydata.init_salt[(mydata.init_t >= starttime) & (mydata.init_t <= endtime)]\n",
    "    temp = mydata.init_temp[(mydata.init_t >= starttime) & (mydata.init_t <= endtime)]\n",
    "    depth = depthf(mydata.init_z[(mydata.init_t >= starttime) & (mydata.init_t <= endtime)]-1.)[0]\n",
    "    section = mydata.final_section[(mydata.init_t >= starttime) & (mydata.init_t <= endtime)]\n",
    "    trans = mydata.init_transp[(mydata.init_t >= starttime) & (mydata.init_t <= endtime)]/(endtime-starttime+1)\n",
    "    return salt, temp, depth, section, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymesh = xr.open_dataset('/home/sallen/MEOPAR/grid/mesh_mask201702.nc')\n",
    "depthf = interp.interp1d(mymesh.z, mymesh.gdept_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section numbers\n",
    "meander = 0\n",
    "admiralty = 2\n",
    "deception = 3\n",
    "rosario = 4\n",
    "sanjuan = 5\n",
    "haro = 6\n",
    "sec_name = ['meander', 'admiralty', 'deception', 'rosario', 'sanjuan', 'haro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summer 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearjumps = [0,1,-2,1,0,1,0,1,1,0,1,0]\n",
    "str_mo = ['jan', 'feb', 'mar', 'apr','may', 'jun', 'jul', 'aug', 'sep','oct', 'nov', 'dec']\n",
    "sum_start = 1+(5*720+(sum(yearjumps[:5+1]*24)))\n",
    "sum_end = 720+(8*720+(sum(yearjumps[:8+1]*24)))\n",
    "\n",
    "file = '/ocean/rbeutel/MOAD/analysis-becca/Ariane/1yr_runs/201905_1hr/forward_01jan17/ariane_positions_quantitative.nc'\n",
    "mydata = xr.open_dataset(file)\n",
    "salt, temp, depth, section, trans = get_data(mydata, sum_start, sum_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'salt': salt, 'temp': temp, 'depth':depth, 'section':section, 'transport':trans}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "upwelled = df[df.depth <= 200]\n",
    "cuc = df[df.depth > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.73213662963585, 6.267863370364149]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sum(upwelled.transport)/np.sum(df.transport)*100,np.sum(cuc.transport)/np.sum(df.transport)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 81.38937375212231\n",
      "haro = 13.237420502107383\n",
      "sanjuan = 0.7064967587767096\n",
      "rosario = 1.4683930037920245\n",
      "admiralty = 3.1828024570276363\n",
      "deception = 0.015434759321449222\n"
     ]
    }
   ],
   "source": [
    "# lets see what sections these groups get into \n",
    "# first upwelled\n",
    "print('advects back out = ' + str(sum(upwelled.transport[upwelled.section == meander])/np.sum(upwelled.transport)*100))\n",
    "print('haro = ' + str(sum(upwelled.transport[upwelled.section == haro])/np.sum(upwelled.transport)*100))\n",
    "print('sanjuan = ' + str(sum(upwelled.transport[upwelled.section == sanjuan])/np.sum(upwelled.transport)*100))\n",
    "print('rosario = ' + str(sum(upwelled.transport[upwelled.section == rosario])/np.sum(upwelled.transport)*100))\n",
    "print('admiralty = ' + str(sum(upwelled.transport[upwelled.section == admiralty])/np.sum(upwelled.transport)*100))\n",
    "print('deception = ' + str(sum(upwelled.transport[upwelled.section == deception])/np.sum(upwelled.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 88.46222790645251\n",
      "haro = 8.610096977372251\n",
      "sanjuan = 0.4545295871380527\n",
      "rosario = 0.8177067747539721\n",
      "admiralty = 1.6480737956203904\n",
      "deception = 0.007364958662847872\n"
     ]
    }
   ],
   "source": [
    "# and deep\n",
    "print('advects back out = ' + str(sum(cuc.transport[cuc.section == meander])/np.sum(cuc.transport)*100))\n",
    "print('haro = ' + str(sum(cuc.transport[cuc.section == haro])/np.sum(cuc.transport)*100))\n",
    "print('sanjuan = ' + str(sum(cuc.transport[cuc.section == sanjuan])/np.sum(cuc.transport)*100))\n",
    "print('rosario = ' + str(sum(cuc.transport[cuc.section == rosario])/np.sum(cuc.transport)*100))\n",
    "print('admiralty = ' + str(sum(cuc.transport[cuc.section == admiralty])/np.sum(cuc.transport)*100))\n",
    "print('deception = ' + str(sum(cuc.transport[cuc.section == deception])/np.sum(cuc.transport)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winter 2016/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearjumps = [0,1,-2,1,0,1,0,1,1,0,1,0]\n",
    "str_mo = ['jan', 'feb', 'mar', 'apr','may', 'jun', 'jul', 'aug', 'sep','oct', 'nov', 'dec']\n",
    "win_start = 1+(9*720+(sum(yearjumps[:9+1]*24)))\n",
    "win_end = 720+(11*720+(sum(yearjumps[:11+1]*24)))\n",
    "\n",
    "file = '/ocean/rbeutel/MOAD/analysis-becca/Ariane/1yr_runs/201905_1hr/forward_01jan16/ariane_positions_quantitative.nc'\n",
    "mydata = xr.open_dataset(file)\n",
    "saltW, tempW, depthW, sectionW, transW = get_data(mydata, win_start, win_end)\n",
    "\n",
    "win_start = 1+(0*720+(sum(yearjumps[:0+1]*24)))\n",
    "win_end = 720+(5*720+(sum(yearjumps[:5+1]*24)))\n",
    "\n",
    "file = '/ocean/rbeutel/MOAD/analysis-becca/Ariane/1yr_runs/201905_1hr/forward_01jan17/ariane_positions_quantitative.nc'\n",
    "mydata = xr.open_dataset(file)\n",
    "saltS, tempS, depthS, sectionS, transS = get_data(mydata, win_start, win_end)\n",
    "\n",
    "salt = np.append(saltW, saltS)\n",
    "temp = np.append(tempW, tempS)\n",
    "depth = np.append(depthW, depthS)\n",
    "section = np.append(sectionW, sectionS)\n",
    "trans = np.append(transW, transS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'salt': salt, 'temp': temp, 'depth':depth, 'section':section, 'transport':trans}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "upwelled = df[(df.depth <= 200) & (df.salt >= 32.4)]\n",
    "cuc = df[(df.depth > 200) & (df.salt >= 32.4)]\n",
    "columbia = df[(df.salt < 32.4) & (df.temp >= 10.7)]\n",
    "coldF = df[(df.salt < 32.4) & (df.temp < 10.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53.93843695128463, 6.166366356170525, 12.21886924572361, 27.67632744682128]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sum(upwelled.transport)/np.sum(df.transport)*100,np.sum(cuc.transport)/np.sum(df.transport)*100,\n",
    "np.sum(columbia.transport)/np.sum(df.transport)*100,np.sum(coldF.transport)/np.sum(df.transport)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 84.82765618044542\n",
      "haro = 10.052585541846364\n",
      "sanjuan = 0.5810074713520935\n",
      "rosario = 1.0484117680470646\n",
      "admiralty = 3.259665938453609\n",
      "deception = 0.011176476026704643\n"
     ]
    }
   ],
   "source": [
    "# lets see what sections these groups get into \n",
    "# first upwelled\n",
    "print('advects back out = ' + str(sum(upwelled.transport[upwelled.section == meander])/np.sum(upwelled.transport)*100))\n",
    "print('haro = ' + str(sum(upwelled.transport[upwelled.section == haro])/np.sum(upwelled.transport)*100))\n",
    "print('sanjuan = ' + str(sum(upwelled.transport[upwelled.section == sanjuan])/np.sum(upwelled.transport)*100))\n",
    "print('rosario = ' + str(sum(upwelled.transport[upwelled.section == rosario])/np.sum(upwelled.transport)*100))\n",
    "print('admiralty = ' + str(sum(upwelled.transport[upwelled.section == admiralty])/np.sum(upwelled.transport)*100))\n",
    "print('deception = ' + str(sum(upwelled.transport[upwelled.section == deception])/np.sum(upwelled.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 93.48854029970028\n",
      "haro = 4.305421294243852\n",
      "sanjuan = 0.260153862976561\n",
      "rosario = 0.4206077366042773\n",
      "admiralty = 1.3420340829031492\n",
      "deception = 0.0028524863047357826\n"
     ]
    }
   ],
   "source": [
    "# and deep\n",
    "print('advects back out = ' + str(sum(cuc.transport[cuc.section == meander])/np.sum(cuc.transport)*100))\n",
    "print('haro = ' + str(sum(cuc.transport[cuc.section == haro])/np.sum(cuc.transport)*100))\n",
    "print('sanjuan = ' + str(sum(cuc.transport[cuc.section == sanjuan])/np.sum(cuc.transport)*100))\n",
    "print('rosario = ' + str(sum(cuc.transport[cuc.section == rosario])/np.sum(cuc.transport)*100))\n",
    "print('admiralty = ' + str(sum(cuc.transport[cuc.section == admiralty])/np.sum(cuc.transport)*100))\n",
    "print('deception = ' + str(sum(cuc.transport[cuc.section == deception])/np.sum(cuc.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 95.46860207507646\n",
      "haro = 2.5278198648165646\n",
      "sanjuan = 0.18915306618356834\n",
      "rosario = 0.2884615409518763\n",
      "admiralty = 1.5074949537499662\n",
      "deception = 0.0029119133068299546\n"
     ]
    }
   ],
   "source": [
    "# columbia \n",
    "print('advects back out = ' + str(sum(columbia.transport[columbia.section == meander])/np.sum(columbia.transport)*100))\n",
    "print('haro = ' + str(sum(columbia.transport[columbia.section == haro])/np.sum(columbia.transport)*100))\n",
    "print('sanjuan = ' + str(sum(columbia.transport[columbia.section == sanjuan])/np.sum(columbia.transport)*100))\n",
    "print('rosario = ' + str(sum(columbia.transport[columbia.section == rosario])/np.sum(columbia.transport)*100))\n",
    "print('admiralty = ' + str(sum(columbia.transport[columbia.section == admiralty])/np.sum(columbia.transport)*100))\n",
    "print('deception = ' + str(sum(columbia.transport[columbia.section == deception])/np.sum(columbia.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 97.60974873439106\n",
      "haro = 1.413398694821987\n",
      "sanjuan = 0.1055362301996183\n",
      "rosario = 0.1611048628052375\n",
      "admiralty = 0.6685709219620392\n",
      "deception = 0.0019854090112765596\n"
     ]
    }
   ],
   "source": [
    "# and myterious colder fresh that may still be columbia\n",
    "print('advects back out = ' + str(sum(coldF.transport[coldF.section == meander])/np.sum(coldF.transport)*100))\n",
    "print('haro = ' + str(sum(coldF.transport[coldF.section == haro])/np.sum(coldF.transport)*100))\n",
    "print('sanjuan = ' + str(sum(coldF.transport[coldF.section == sanjuan])/np.sum(coldF.transport)*100))\n",
    "print('rosario = ' + str(sum(coldF.transport[coldF.section == rosario])/np.sum(coldF.transport)*100))\n",
    "print('admiralty = ' + str(sum(coldF.transport[coldF.section == admiralty])/np.sum(coldF.transport)*100))\n",
    "print('deception = ' + str(sum(coldF.transport[coldF.section == deception])/np.sum(coldF.transport)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winter 2017/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearjumps = [0,1,-2,1,0,1,0,1,1,0,1,0]\n",
    "str_mo = ['jan', 'feb', 'mar', 'apr','may', 'jun', 'jul', 'aug', 'sep','oct', 'nov', 'dec']\n",
    "win_start = 1+(9*720+(sum(yearjumps[:9+1]*24)))\n",
    "win_end = 720+(11*720+(sum(yearjumps[:11+1]*24)))\n",
    "\n",
    "file = '/ocean/rbeutel/MOAD/analysis-becca/Ariane/1yr_runs/201905_1hr/forward_01jan17/ariane_positions_quantitative.nc'\n",
    "mydata = xr.open_dataset(file)\n",
    "salt17, temp17, depth17, section17, trans17 = get_data(mydata, win_start, win_end)\n",
    "\n",
    "start = 1\n",
    "end = 720\n",
    "\n",
    "file = '/ocean/rbeutel/MOAD/analysis-becca/Ariane/201905_1hr/forward_01jan18/ariane_positions_quantitative.nc'\n",
    "mydata = xr.open_dataset(file)\n",
    "salt_jan, temp_jan, depth_jan, section_jan, trans_jan = get_data(mydata, start, end)\n",
    "\n",
    "file = '/ocean/rbeutel/MOAD/analysis-becca/Ariane/201905_1hr/forward_01feb18/ariane_positions_quantitative.nc'\n",
    "mydata = xr.open_dataset(file)\n",
    "salt_feb, temp_feb, depth_feb, section_feb, trans_feb = get_data(mydata, start, end)\n",
    "\n",
    "file = '/ocean/rbeutel/MOAD/analysis-becca/Ariane/201905_1hr/forward_01mar18/ariane_positions_quantitative.nc'\n",
    "mydata = xr.open_dataset(file)\n",
    "salt_mar, temp_mar, depth_mar, section_mar, trans_mar = get_data(mydata, start, end)\n",
    "\n",
    "salt = np.append(np.append(np.append(salt17, salt_jan), salt_feb), salt_mar)\n",
    "temp = np.append(np.append(np.append(temp17, temp_jan), temp_feb), temp_mar)\n",
    "depth = np.append(np.append(np.append(depth17, depth_jan), depth_feb), depth_mar)\n",
    "section = np.append(np.append(np.append(section17, section_jan), section_feb), section_mar)\n",
    "trans = np.append(np.append(np.append(trans17, trans_jan), trans_feb), trans_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'salt': salt, 'temp': temp, 'depth':depth, 'section':section, 'transport':trans}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "upwelled = df[(df.depth <= 200) & (df.salt >= 31.8) & (df.temp <= 9.8)]\n",
    "cuc = df[(df.depth > 200) & (df.salt >= 31.8) & (df.temp <= 9.8)]\n",
    "columbia = df[(df.temp > 9.8)]\n",
    "coldF = df[(df.salt < 31.8) & (df.temp < 9.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67.65680137196978, 6.095397136901457, 2.910667440202735, 23.337134050926053]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sum(upwelled.transport)/np.sum(df.transport)*100,np.sum(cuc.transport)/np.sum(df.transport)*100,\n",
    "np.sum(columbia.transport)/np.sum(df.transport)*100,np.sum(coldF.transport)/np.sum(df.transport)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 84.48769768837384\n",
      "haro = 9.512216135860179\n",
      "sanjuan = 0.5948117849499793\n",
      "rosario = 0.949235722815569\n",
      "admiralty = 3.2630895839510474\n",
      "deception = 0.011524260302600666\n"
     ]
    }
   ],
   "source": [
    "# lets see what sections these groups get into \n",
    "# first upwelled\n",
    "print('advects back out = ' + str(sum(upwelled.transport[upwelled.section == meander])/np.sum(upwelled.transport)*100))\n",
    "print('haro = ' + str(sum(upwelled.transport[upwelled.section == haro])/np.sum(upwelled.transport)*100))\n",
    "print('sanjuan = ' + str(sum(upwelled.transport[upwelled.section == sanjuan])/np.sum(upwelled.transport)*100))\n",
    "print('rosario = ' + str(sum(upwelled.transport[upwelled.section == rosario])/np.sum(upwelled.transport)*100))\n",
    "print('admiralty = ' + str(sum(upwelled.transport[upwelled.section == admiralty])/np.sum(upwelled.transport)*100))\n",
    "print('deception = ' + str(sum(upwelled.transport[upwelled.section == deception])/np.sum(upwelled.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 92.6043680365625\n",
      "haro = 4.5736470339224535\n",
      "sanjuan = 0.2979765798597585\n",
      "rosario = 0.47534916550493256\n",
      "admiralty = 1.3799345621068348\n",
      "deception = 0.0064622023368504766\n"
     ]
    }
   ],
   "source": [
    "# and deep\n",
    "print('advects back out = ' + str(sum(cuc.transport[cuc.section == meander])/np.sum(cuc.transport)*100))\n",
    "print('haro = ' + str(sum(cuc.transport[cuc.section == haro])/np.sum(cuc.transport)*100))\n",
    "print('sanjuan = ' + str(sum(cuc.transport[cuc.section == sanjuan])/np.sum(cuc.transport)*100))\n",
    "print('rosario = ' + str(sum(cuc.transport[cuc.section == rosario])/np.sum(cuc.transport)*100))\n",
    "print('admiralty = ' + str(sum(cuc.transport[cuc.section == admiralty])/np.sum(cuc.transport)*100))\n",
    "print('deception = ' + str(sum(cuc.transport[cuc.section == deception])/np.sum(cuc.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 92.74943674918838\n",
      "haro = 3.521841332016041\n",
      "sanjuan = 0.262490034609221\n",
      "rosario = 0.456335502099864\n",
      "admiralty = 2.941398331565594\n",
      "deception = 0.003391871578109074\n"
     ]
    }
   ],
   "source": [
    "# columbia \n",
    "print('advects back out = ' + str(sum(columbia.transport[columbia.section == meander])/np.sum(columbia.transport)*100))\n",
    "print('haro = ' + str(sum(columbia.transport[columbia.section == haro])/np.sum(columbia.transport)*100))\n",
    "print('sanjuan = ' + str(sum(columbia.transport[columbia.section == sanjuan])/np.sum(columbia.transport)*100))\n",
    "print('rosario = ' + str(sum(columbia.transport[columbia.section == rosario])/np.sum(columbia.transport)*100))\n",
    "print('admiralty = ' + str(sum(columbia.transport[columbia.section == admiralty])/np.sum(columbia.transport)*100))\n",
    "print('deception = ' + str(sum(columbia.transport[columbia.section == deception])/np.sum(columbia.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advects back out = 97.33664742878084\n",
      "haro = 1.3138447959238753\n",
      "sanjuan = 0.09233904049191399\n",
      "rosario = 0.18328809458081916\n",
      "admiralty = 0.8120089115428383\n",
      "deception = 0.0027974182462729125\n"
     ]
    }
   ],
   "source": [
    "# and myterious colder fresh that may still be columbia\n",
    "print('advects back out = ' + str(sum(coldF.transport[coldF.section == meander])/np.sum(coldF.transport)*100))\n",
    "print('haro = ' + str(sum(coldF.transport[coldF.section == haro])/np.sum(coldF.transport)*100))\n",
    "print('sanjuan = ' + str(sum(coldF.transport[coldF.section == sanjuan])/np.sum(coldF.transport)*100))\n",
    "print('rosario = ' + str(sum(coldF.transport[coldF.section == rosario])/np.sum(coldF.transport)*100))\n",
    "print('admiralty = ' + str(sum(coldF.transport[coldF.section == admiralty])/np.sum(coldF.transport)*100))\n",
    "print('deception = ' + str(sum(coldF.transport[coldF.section == deception])/np.sum(coldF.transport)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariane",
   "language": "python",
   "name": "ariane"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
